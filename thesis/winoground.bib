@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{antol2015vqa,
  title={VQA: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={ICCV},
  year={2015}
}

@inproceedings{birhane2021multimodal,
  title={Multimodal datasets: misogyny, pornography, and malignant stereotypes},
  author={Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  booktitle={arXiv preprint arXiv:2110.01963},
  year={2021}
}

@inproceedings{bugliarello2020unmasked,
   author = {Emanuele Bugliarello and Ryan Cotterell and Naoaki Okazaki and Desmond Elliott},
   title = {Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework of Vision-and-Language BERTs},
   booktitle = {arXiv preprint arXiv:2011.15124},
   year = {2020},
}

@inproceedings{chao2017being,
  title={Being negative but constructively: Lessons learnt from creating better visual question answering datasets},
  author={Chao, Wei-Lun and Hu, Hexiang and Sha, Fei},
  booktitle={arXiv preprint arXiv:1704.07121},
  year={2017}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{devlin2019bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "NAACL: Human Language Technologies",
    year = "2019",
}

@inproceedings{ding2016understanding,
  title={Understanding image and text simultaneously: a dual vision-language machine comprehension task},
  author={Ding, Nan and Goodman, Sebastian and Sha, Fei and Soricut, Radu},
  booktitle={arXiv preprint arXiv:1612.07833},
  year={2016}
}

@inproceedings{dosovitskiy2020imageworth,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}},
  booktitle   = {ICLR},
  year      = {2021},
}

@inproceedings{elazar2021back,
  title={Back to Square One: Artifact Detection, Training and Commonsense Disentanglement in the Winograd Schema},
  author={Elazar, Yanai and Zhang, Hongming and Goldberg, Yoav and Roth, Dan},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{frank2021visionforlang,
  title={Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers},
  author={Stella Frank and Emanuele Bugliarello and Desmond Elliott},
  booktitle={EMNLP},
  year={2021}
}

@article{liu2021cultures,
  title={Visually Grounded Reasoning across Languages and Cultures},
  author={Fangyu Liu and Emanuele Bugliarello and E. Ponti and Siva Reddy and Nigel Collier and Desmond Elliott},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.13238}
}

@inproceedings{faghri2018vse,
  title={VSE++: Improving Visual-Semantic Embeddings with Hard Negatives},
  author={Fartash Faghri and David J. Fleet and Jamie Ryan Kiros and Sanja Fidler},
  booktitle={BMVC},
  year={2018}
}

@article{frank2021vision,
  title={Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers},
  author={Frank, Stella and Bugliarello, Emanuele and Elliott, Desmond},
  journal={arXiv preprint arXiv:2109.04448},
  year={2021}
}

@inproceedings{gan2020villa,
   author = {Zhe Gan and Yen-Chun Chen and Linjie Li and Chen Zhu and Yu Cheng and Jingjing Liu},
   title = {Large-Scale Adversarial Training for Vision-and-Language Representation Learning},
   booktitle={NeurIPS},
   year = {2020},
}

@inproceedings{gomez2020exploring,
  title={Exploring hate speech detection in multimodal publications},
  author={Gomez, Raul and Gibert, Jaume and Gomez, Lluis and Karatzas, Dimosthenis},
  booktitle={ICCV},
  year={2020}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{hendricks2021decoupling,
  title={Decoupling the role of data, attention, and losses in multimodal transformers},
  author={Hendricks, Lisa Anne and Mellor, John and Schneider, Rosalia and Alayrac, Jean-Baptiste and Nematzadeh, Aida},
  booktitle={arXiv preprint arXiv:2102.00529},
  year={2021}
}

@inproceedings{hendricks2021probing,
    title = "Probing Image-Language Transformers for Verb Understanding",
    author = "Hendricks, Lisa Anne  and Nematzadeh, Aida",
    booktitle = "ACL-IJCNLP",
    year = "2021",
}

@inproceedings{hendrycks2021natural,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{hosseinmardi2015detection,
  title={Detection of cyberbullying incidents on the instagram social network},
  author={Hosseinmardi, Homa and Mattson, Sabrina Arredondo and Rafiq, Rahat Ibn and Han, Richard and Lv, Qin and Mishra, Shivakant},
  booktitle={arXiv preprint arXiv:1503.03909},
  year={2015}
}

@inproceedings{hu2019evaluating,
  title={Evaluating text-to-image matching using binary image selection (bison)},
  author={Hu, Hexiang and Misra, Ishan and van der Maaten, Laurens},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{hu2021unit,
   author = {Ronghang Hu and Amanpreet Singh},
   title = {UniT: Multimodal Multitask Learning with a Unified Transformer},
   booktitle={arXiv preprint arXiv:2102.10772},
   year = {2021},
}

@inproceedings{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  booktitle={arXiv preprint arXiv:2005.04790},
  year={2020}
}


@inproceedings{kim2021vilt,
   author = {Wonjae Kim and Bokyung Son and Ildoo Kim},
   title = {ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
   booktitle={ICML},
   year = {2021},
}

@inproceedings{kocijan2020review,
  title={A Review of Winograd Schema Challenge Datasets and Approaches},
  author={Kocijan, Vid and Lukasiewicz, Thomas and Davis, Ernest and Marcus, Gary and Morgenstern, Leora},
  booktitle={arXiv preprint arXiv:2004.13831},
  year={2020}
}

@inproceedings{krishna2016visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  booktitle={arXiv preprint arXiv:1602.07332},
  year={2016}
}

@article{lee2018stacked,
  title={Stacked Cross Attention for Image-Text Matching},
  author={Kuang-Huei Lee and Xi Chen and Gang Hua and Houdong Hu and Xiaodong He},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.08024}
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Conference on the Principles of Knowledge Representation and Reasoning},
  year={2012}
}

@inproceedings{li2019vsrn,
  title={Visual semantic reasoning for image-text matching},
  author={Li, Kunpeng and Zhang, Yulun and Li, Kai and Li, Yuanyuan and Fu, Yun},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{li2019visualbert,
  title = {{VisualBERT: A Simple and Performant Baseline for Vision and Language}},
  author = {Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  booktitle = {arXiv preprint arXiv:1908.03557},
  year = {2019}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014},
}

@inproceedings{liu2020precise,
   author = {Haokun Liu and William Huang and Dhara Mungra and Samuel R. Bowman},
   title = {Precise Task Formalization Matters in Winograd Schema Evaluations},
   booktitle={EMNLP},
   year = {2020},
}

@inproceedings{lu2019vilbert,
  title = {{ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks}},
  author = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle = {NeurIPS},
  year = {2019}
}

@inproceedings{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{parcalabescu2020seeingpw,
  title={Seeing past words: Testing the cross-modal capabilities of pretrained V\&L models},
  author={Letitia Parcalabescu and Albert Gatt and Anette Frank and Iacer Calixto},
  booktitle={Workshop on Multimodal Semantic Representations (MMSR)},
  year={2020},
}

@inproceedings{radford2021clip,
   author = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
   title = {Learning Transferable Visual Models From Natural Language Supervision},
   booktitle={ICML},
   year = {2021},
}

@inproceedings{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={NeurIPS},
  year={2015}
}

@inproceedings{rudinger2018gender,
  title={Gender bias in coreference resolution},
  author={Rudinger, Rachel and Naradowsky, Jason and Leonard, Brian and Van Durme, Benjamin},
  booktitle={arXiv preprint arXiv:1804.09301},
  year={2018}
}

@inproceedings{sakaguchi2020winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{gulordava2018,
    title = "Colorless Green Recurrent Networks Dream Hierarchically",
    author = "Gulordava, Kristina  and
      Bojanowski, Piotr  and
      Grave, Edouard  and
      Linzen, Tal  and
      Baroni, Marco",
    booktitle = "NAACL: Human Language Technologies",
    year = "2018",
}

@inproceedings{thrush2020investigating,
    title = "Investigating Novel Verb Learning in {BERT}: Selectional Preference Classes and Alternation-Based Syntactic Generalization",
    author = "Thrush, Tristan  and
      Wilcox, Ethan  and
      Levy, Roger",
    booktitle = "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    year = "2020",
}

@inproceedings{linzen2016assessing,
  title={Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies},
  author={Tal Linzen and Emmanuel Dupoux and Yoav Goldberg},
  booktitle={TACL},
  year={2015},
}

@misc{getty,
  key={getty},
  howpublished = {\url{https://www.gettyimages.com/}}
}

@book{altshuler2019course,
    title={A Course in Semantics},
    author={Daniel Altshuler and Terence Parsons and Roger Schwarzschild},
    publisher={MIT Press},
    year={2019}
}

@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    year   = {2017},
}

@inproceedings{honnibal2015improved,
    title = "An Improved Non-monotonic Transition System for Dependency Parsing",
    author = "Honnibal, Matthew  and
      Johnson, Mark",
    booktitle = "EMNLP",
    year = "2015",
}

@inproceedings{choi2012context,
  title={Context Models and Out-of-context Objects},
  author={Myung Jin Choi and Antonio Torralba and Alan S. Willsky},
  booktitle={Pattern Recognition Letters},
  year={2012}
}

@inproceedings{hendrycks2019robustness,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Dan Hendrycks and Thomas Dietterich},
  booktitle={ICLR},
  year={2019}
}


@inproceedings{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

@inproceedings{shekhar2017foil,
   title={"FOIL it! Find One mismatch between Image and Language caption"},
   author={Shekhar, Ravi and Pezzelle, Sandro and Klimovich, Yauhen and Herbelot, Aurelie and Nabi, Moin and Sangineto, Enver and Bernardi, Raffaella},
   booktitle = {ACL},
   year={2017}
}


@inproceedings{sinha2020unnatural,
author = {Koustuv Sinha and Prasanna Parthasarathi and Joelle Pineau and Adina Williams},
   title = {UnNatural Language Inference},
   booktitle={ACL},
   year = {2020},
}

@inproceedings{sinha2021matterslittle,
   author = {Koustuv Sinha and Robin Jia and Dieuwke Hupkes and Joelle Pineau and Adina Williams and Douwe Kiela},
   title = {Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little},
   booktitle={EMNLP},
   year = {2021},
}

@inproceedings{suryawanshi2021trollmeme,
    title = "Findings of the Shared Task on Troll Meme Classification in {T}amil",
    author = "Suryawanshi, Shardul  and
      Chakravarthi, Bharathi Raja",
    booktitle = "Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages",
    year = "2021",
}

@inproceedings{tan2020lxmert,
   author = {Hao Tan and Mohit Bansal},
   booktitle = {EMNLP-IJCNLP},
   title = {LXMert: Learning cross-modality encoder representations from transformers},
   year = {2020},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{yang2020object,
  title={Object-Centric Diagnosis of Visual Reasoning},
  author={Yang, Jianwei and Mao, Jiayuan and Wu, Jiajun and Parikh, Devi and Cox, David D and Tenenbaum, Joshua B and Gan, Chuang},
  booktitle={arXiv preprint arXiv:2012.11587},
  year={2020}
}

@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{zhao2018gender,
  title={Gender bias in coreference resolution: Evaluation and debiasing methods},
  author={Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Ordonez, Vicente and Chang, Kai-Wei},
  booktitle={arXiv preprint arXiv:1804.06876},
  year={2018}
}

@inproceedings{zhong2016content,
  title={Content-Driven Detection of Cyberbullying on the Instagram Social Network.},
  author={Zhong, Haoti and Li, Hao and Squicciarini, Anna Cinzia and Rajtmajer, Sarah Michele and Griffin, Christopher and Miller, David J and Caragea, Cornelia},
  booktitle={IJCAI},
  year={2016}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{sheng2021human,
  title={Human-Adversarial Visual Question Answering},
  author={Sheng, Sasha and Singh, Amanpreet and Goswami, Vedanuj and Magana, Jose Alberto Lopez and Thrush, Tristan and Galuba, Wojciech and Parikh, Devi and Kiela, Douwe},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={CVPR},
  year={2019}
}
@inproceedings{sidorov2020textcaps,
  title={Textcaps: a dataset for image captioning with reading comprehension},
  author={Sidorov, Oleksii and Hu, Ronghang and Rohrbach, Marcus and Singh, Amanpreet},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{sinha-etal-2021-unnatural,
    title = "{UnNatural} {L}anguage {I}nference",
    author = "Sinha, Koustuv  and
      Parthasarathi, Prasanna  and
      Pineau, Joelle  and
      Williams, Adina",
    booktitle = "ACL-IJCNLP",
    year = "2021",
}

@inproceedings{vedantam2021curi,
  title={Curi: A benchmark for productive concept learning under uncertainty},
  author={Vedantam, Ramakrishna and Szlam, Arthur and Nickel, Maximillian and Morcos, Ari and Lake, Brenden M},
  booktitle={ICML},
  year={2021},
}

@inproceedings{suhr2017corpus,
  title={A corpus of natural language for visual reasoning},
  author={Suhr, Alane and Lewis, Mike and Yeh, James and Artzi, Yoav},
  booktitle={ACL},
  year={2017}
}

@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{kirk2021hatemoji,
  title={Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based Hate},
  author={Kirk, Hannah Rose and Vidgen, Bertram and R{\"o}ttger, Paul and Thrush, Tristan and Hale, Scott A},
  booktitle={arXiv preprint arXiv:2108.05921},
  year={2021}
}

@inproceedings{parthasarathi-etal-2021-sometimes-want,
    title = "Sometimes We Want Ungrammatical Translations",
    author = "Parthasarathi, Prasanna  and
      Sinha, Koustuv  and
      Pineau, Joelle  and
      Williams, Adina",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP",
    year = "2021",
}

@inproceedings{williams-etal-2018-latent,
    title = "Do latent tree learning models identify meaningful structure in sentences?",
    author = "Williams, Adina  and
      Drozdov, Andrew  and
      Bowman, Samuel R.",
    booktitle = "TACL",
    year = "2018",
}

@inproceedings{warstadt-etal-2020-blimp-benchmark,
    title = "{BL}i{MP}: The Benchmark of Linguistic Minimal Pairs for {E}nglish",
    author = "Warstadt, Alex  and
      Parrish, Alicia  and
      Liu, Haokun  and
      Mohananey, Anhad  and
      Peng, Wei  and
      Wang, Sheng-Fu  and
      Bowman, Samuel R.",
    booktitle = "TACL",
    year = "2020",
}

@inproceedings{hu-etal-2020-systematic,
    title = "A Systematic Assessment of Syntactic Generalization in Neural Language Models",
    author = "Hu, Jennifer  and
      Gauthier, Jon  and
      Qian, Peng  and
      Wilcox, Ethan  and
      Levy, Roger",
    booktitle = "ACL",
    year = "2020",
}

@inproceedings{gauthier-etal-2020-syntaxgym,
    title = "{S}yntax{G}ym: An Online Platform for Targeted Evaluation of Language Models",
    author = "Gauthier, Jon  and
      Hu, Jennifer  and
      Wilcox, Ethan  and
      Qian, Peng  and
      Levy, Roger",
    booktitle = "ACL: System Demonstrations",
    year = "2020",
}

@inproceedings{warstadt-etal-2019-investigating,
    title = "Investigating {BERT}{'}s Knowledge of Language: Five Analysis Methods with {NPI}s",
    author = "Warstadt, Alex  and
      Cao, Yu  and
      Grosu, Ioana  and
      Peng, Wei  and
      Blix, Hagen  and
      Nie, Yining  and
      Alsop, Anna  and
      Bordia, Shikha  and
      Liu, Haokun  and
      Parrish, Alicia  and
      Wang, Sheng-Fu  and
      Phang, Jason  and
      Mohananey, Anhad  and
      Htut, Phu Mon  and
      Jeretic, Paloma  and
      Bowman, Samuel R.",
    booktitle = "EMNLP-IJCNLP",
    year = "2019",
}

@inproceedings{kann-etal-2019-verb,
    title = "Verb Argument Structure Alternations in Word and Sentence Embeddings",
    author = "Kann, Katharina  and
      Warstadt, Alex  and
      Williams, Adina  and
      Bowman, Samuel R.",
    booktitle = "{SC}i{L}",
    year = "2019",
}

@inproceedings{winograd1972understanding,
  title={Understanding natural language},
  author={Winograd, Terry},
  booktitle={Cognitive psychology},
  year={1972},
}

@inproceedings{bender2015establishing,
  title={Establishing a Human Baseline for the Winograd Schema Challenge.},
  author={Bender, David},
  booktitle={Modern Artificial Intelligence and Cognitive Science},
  year={2015}
}

@inproceedings{cao2020behind,
  title={Behind the scene: Revealing the secrets of pre-trained vision-and-language models},
  author={Cao, Jize and Gan, Zhe and Cheng, Yu and Yu, Licheng and Chen, Yen-Chun and Liu, Jingjing},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{dou2021empirical,
  title={An Empirical Study of Training End-to-End Vision-and-Language Transformers},
  author={Dou, Zi-Yi and Xu, Yichong and Gan, Zhe and Wang, Jianfeng and Wang, Shuohang and Wang, Lijuan and Zhu, Chenguang and Liu, Zicheng and Zeng, Michael and others},
  booktitle={arXiv preprint arXiv:2111.02387},
  year={2021}
}
@inproceedings{li2020closer,
  title={A closer look at the robustness of vision-and-language pre-trained models},
  author={Li, Linjie and Gan, Zhe and Liu, Jingjing},
  booktitle={arXiv preprint arXiv:2012.08673},
  year={2020}
}
@inproceedings{singh2020we,
  title={Are we pretraining it right? digging deeper into visio-linguistic pretraining},
  author={Singh, Amanpreet and Goswami, Vedanuj and Parikh, Devi},
  booktitle={arXiv preprint arXiv:2004.08744},
  year={2020}
}
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{Scheuerman2019gender,
author = {Scheuerman, Morgan Klaus and Paul, Jacob M. and Brubaker, Jed R.},
title = {How Computers See Gender: An Evaluation of Gender Classification in Commercial Facial Analysis Services},
year = {2019},
booktitle = {ACM: Human Computer Interaction},
}

@inproceedings{Socher2013RecursiveDM,
  title={Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
  author={Richard Socher and Alex Perelygin and Jean Wu and Jason Chuang and Christopher D. Manning and A. Ng and Christopher Potts},
  booktitle={EMNLP},
  year={2013}
}


@misc{QQPDataset,
    author={Shankar Iyer and Nikhil Dandekar and Kornel Csernai.},
    title={First Quora dataset release: Question pairs},
    url={https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs},
    year={2017}
}

@inproceedings{williams2017broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  booktitle={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@inproceedings{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@inproceedings{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  booktitle={TACL},
  year={2014},
}

@inproceedings{xie2018visual,
  title={Visual entailment task for visually-grounded language learning},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  booktitle={arXiv preprint arXiv:1811.10582},
  year={2018}
}

@inproceedings{zellers2019recognition,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{chung2014gru,
  title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
  author={Junyoung Chung and Caglar Gulcehr and KyungHyun Cho and Yoshua Bengio},
  booktitle={NeurIPS},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{simonyan2015very,
  title={Very deep convolutional networks for largescale image recognition},
  author={Karen Simonyan and Andrew Zisserman},
  booktitle={CVPR},
  year={2015}
}

@inproceedings{frank-etal-2021-vision,
    title = "Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers",
    author = "Frank, Stella  and
      Bugliarello, Emanuele  and
      Elliott, Desmond",
    booktitle = "EMNLP",
    year = "2021",
}

@inproceedings{liu-etal-2021-visually,
    title = "Visually Grounded Reasoning across Languages and Cultures",
    author = "Liu, Fangyu  and
      Bugliarello, Emanuele  and
      Ponti, Edoardo Maria  and
      Reddy, Siva  and
      Collier, Nigel  and
      Elliott, Desmond",
    booktitle = "EMNLP",
    year = "2021",
}

@inproceedings{bitton-etal-2021-automatic,
    title = "Automatic Generation of Contrast Sets from Scene Graphs: Probing the Compositional Consistency of {GQA}",
    author = "Bitton, Yonatan  and
      Stanovsky, Gabriel  and
      Schwartz, Roy  and
      Elhadad, Michael",
    booktitle = "NAACL: Human Language Technologies",
    year = "2021",
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "EMNLP: System Demonstrations",
    year = "2020",
}

@inproceedings{pont-tuset2020localized-narratives,
    title="Connecting vision and language with localized narratives",
    author="Jordi Pont-Tuset and Jasper Uijlings and Soravit Changpinyo and Radu Soricut and Vittorio Ferrari",
    booktitle="ECCV",
    year="2020",
}

@inproceedings{srinivasan2021wit,
    title="Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning",
    author="Krishna Srinivasan and Karthik Raman and Jiecao Chen and Michael Bendersky and Marc Najork",
    booktitle="arXiv preprint arXiv:2103.01913",
    year="2021",
}

@inproceedings{changpinyo2021conceptual12m,
    title="Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts",
    author="Soravit Changpinyo and Piyush Sharma and Nan Ding and Radu Soricut",
    booktitle="CVPR",
    year="2021",
}

@inproceedings{desai2021redcaps,
    title="RedCaps: Web-curated image-text data created by the people",
    author="Karan Desai and Gaurav Kaul and Zubin Aysola and Justin Johnson",
    booktitle="NeurIPS Datasets and Benchmarks",
    year="2021",
}

@inproceedings{thomee2016yfcc100m,
    author="Bart Thomee and David A Shamma and Gerald Friedland and Benjamin Elizalde and Karl Ni and Douglas Poland and Damian Borth and Li-Jia Li",
    title="Yfcc100m: The new data in multimedia research",
    booktitle="Communications of the ACM",
    year="2016",
}

@inproceedings{singh2022flava,
    author="Amanpreet Singh and Ronghang Hu and Vedanuj Goswami and Guillaume Couairon and Wojciech Galuba and Marcus Rohrbach and Douwe Kiela",
    title="FLAVA: A Foundational Language And Vision Alignment Model",
    booktitle="CVPR",
    year="2022",
}

@inproceedings{akula2020words,
    author="Arjun Akula and Spandana Gella and Yaser Al-Onaizan and Song-Chun Zhu and Siva Reddy",
    title="Words Aren’t Enough, Their Order Matters: On the Robustness of Grounding Visual Referring Expressions",
    booktitle="ACL",
    year="2020",
}

@inproceedings{parcalabescu2021seeing,
    author="Letitia Parcalabescu and Albert Gatt and Anette Frank and Iacer Calixto",
    title="Seeing past words: Testing the cross-modal capabilities of pretrained V\&L models on counting tasks",
    booktitle="ACL",
    year="2021",
}

@inproceedings{bogin2021covr,
    author="Ben Bogin and Shivanshu Gupta and Matt Gardner and Jonathan Berant",
    title="COVR: A Test-Bed for Visually Grounded Compositional Generalization with Real Images",
    booktitle="EMNLP",
    year="2021",
}


