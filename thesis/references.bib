@inproceedings{thrush2022winoground,
  title={Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@article{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@article{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{bender2020climbing,
  title={Climbing towards NLU: On meaning, form, and understanding in the age of data},
  author={Bender, Emily M and Koller, Alexander},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={5185--5198},
  year={2020}
}

@inproceedings{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021}
}

@book{levinson2003space,
  title={Space in language and cognition: Explorations in cognitive diversity},
  author={Levinson, Stephen C and Levinson, Stephen C},
  number={5},
  year={2003},
  publisher={Cambridge University Press}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@article{suhr2018corpus,
  title={A corpus for reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2018}
}

@article{liu2022things,
  title={Things not written in text: Exploring spatial commonsense from visual signals},
  author={Liu, Xiao and Yin, Da and Feng, Yansong and Zhao, Dongyan},
  journal={arXiv preprint arXiv:2203.08075},
  year={2022}
}

@article{cho2022dall,
  title={Dall-eval: Probing the reasoning skills and social biases of text-to-image generative transformers},
  author={Cho, Jaemin and Zala, Abhay and Bansal, Mohit},
  journal={arXiv preprint arXiv:2202.04053},
  year={2022}
}

@inproceedings{bagherinezhad2016elephants,
  title={Are elephants bigger than butterflies? reasoning about sizes of objects},
  author={Bagherinezhad, Hessam and Hajishirzi, Hannaneh and Choi, Yejin and Farhadi, Ali},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{elazar2019large,
  title={How large are lions? inducing distributions over quantitative attributes},
  author={Elazar, Yanai and Mahabal, Abhijit and Ramachandran, Deepak and Bedrax-Weiss, Tania and Roth, Dan},
  journal={arXiv preprint arXiv:1906.01327},
  year={2019}
}

@inproceedings{collell2018acquiring,
  title={Acquiring common sense spatial knowledge through implicit spatial templates},
  author={Collell, Guillem and Van Gool, Luc and Moens, Marie-Francine},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{elu2021inferring,
  title={Inferring spatial relations from textual descriptions of images},
  author={Elu, Aitzol and Azkune, Gorka and de Lacalle, Oier Lopez and Arganda-Carreras, Ignacio and Soroa, Aitor and Agirre, Eneko},
  journal={Pattern Recognition},
  volume={113},
  pages={107847},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{jiang2022pseudo,
  title={Pseudo-q: Generating pseudo language queries for visual grounding},
  author={Jiang, Haojun and Lin, Yuanze and Han, Dongchen and Song, Shiji and Huang, Gao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15513--15523},
  year={2022}
}

@article{liu2022visual,
  title={Visual Spatial Reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={arXiv preprint arXiv:2205.00363},
  year={2022}
}

@article{wang2022unifying,
  title={Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  journal={arXiv preprint arXiv:2202.03052},
  year={2022}
}

@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj√∂rn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{andreas2016neural,
 author = {Jacob Andreas and
Marcus Rohrbach and
Trevor Darrell and
Dan Klein},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/cvpr/AndreasRDK16.bib},
 booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
 doi = {10.1109/CVPR.2016.12},
 pages = {39--48},
 publisher = {{IEEE} Computer Society},
 timestamp = {Thu, 25 May 2017 01:00:00 +0200},
 title = {Neural Module Networks},
 url = {https://doi.org/10.1109/CVPR.2016.12},
 year = {2016}
}

@inproceedings{mirzaee-etal-2021-spartqa,
 address = {Online},
 author = {Mirzaee, Roshanak  and
Rajaby Faghihi, Hossein  and
Ning, Qiang  and
Kordjamshidi, Parisa},
 booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 doi = {10.18653/v1/2021.naacl-main.364},
 pages = {4582--4598},
 publisher = {Association for Computational Linguistics},
 title = {{SPARTQA}: A Textual Question Answering Benchmark for Spatial Reasoning},
 url = {https://aclanthology.org/2021.naacl-main.364},
 year = {2021}
}

@inproceedings{liu2019clevr,
 author = {Runtao Liu and
Chenxi Liu and
Yutong Bai and
Alan L. Yuille},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/cvpr/LiuLBY19.bib},
 booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
2019, Long Beach, CA, USA, June 16-20, 2019},
 doi = {10.1109/CVPR.2019.00431},
 pages = {4185--4194},
 publisher = {Computer Vision Foundation / {IEEE}},
 timestamp = {Mon, 20 Jan 2020 00:00:00 +0100},
 title = {CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions},
 url = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Liu\_CLEVR-Ref\_Diagnosing\_Visual\_Reasoning\_With\_Referring\_Expressions\_CVPR\_2019\_paper.html},
 year = {2019}
}

@inproceedings{suhr-etal-2017-corpus,
    title = "A Corpus of Natural Language for Visual Reasoning",
    author = "Suhr, Alane  and
      Lewis, Mike  and
      Yeh, James  and
      Artzi, Yoav",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-2034",
    doi = "10.18653/v1/P17-2034",
    pages = "217--223",
    abstract = "We present a new visual reasoning language dataset, containing 92,244 pairs of examples of natural statements grounded in synthetic images with 3,962 unique sentences. We describe a method of crowdsourcing linguistically-diverse data, and present an analysis of our data. The data demonstrates a broad set of linguistic phenomena, requiring visual and set-theoretic reasoning. We experiment with various models, and show the data presents a strong challenge for future research.",
}

@inproceedings{
schuhmann2022laionb,
title={{LAION}-5B: An open large-scale dataset for training next generation image-text models},
author={Christoph Schuhmann and Romain Beaumont and Cade W Gordon and Ross Wightman and mehdi cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Patrick Schramowski and Srivatsa R Kundurthy and Katherine Crowson and Mitchell Wortsman and Richard Vencu and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2022},
url={https://openreview.net/forum?id=M3Y74vmsMcY}
}

@misc{ilharco_gabriel_2021_5143773,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@article{liu2022compositional,
  title={Compositional Visual Generation with Composable Diffusion Models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:2206.01714},
  year={2022}
}

@inproceedings{
anonymous2023trainingfree,
title={Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis},
author={Anonymous},
booktitle={Submitted to The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=PUIqjT4rzq7},
note={under review}
}

@misc{labelstudio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/heartexlabs/label-studio},
  note={Open source software available from https://github.com/heartexlabs/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2022},
}