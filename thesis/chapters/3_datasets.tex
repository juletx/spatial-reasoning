This chapter introduces the datasets and metrics we used.

\section{Winoground}

\subsection{Dataset}

\subsection{Metrics}

\subsubsection{Score}

Performance on Winoground \cite{thrush2022winoground} is computed according to three different metrics that evaluate different aspects of the models' visio-linguistic reasoning abilities.

The first metric is the \textbf{text score}, which measures whether a model can select the correct caption, given an image. 
Given images $I_0$ and $I_{1}$ and captions $C_{0}$ and $C_{1}$, the text score for an example $(C_{0},I_{0},C_{1},I_{1})$ is computed according to:
\begin{equation}\label{eq:text-score}
        ts(C_{0},I_{0},C_{1},I_{1})= 
    \begin{cases}
        1 & \text{if}\  s(C_{0}, I_{0}) > s(C_{1}, I_{0}) \\
        & \ \ \text{and}\ s(C_{1}, I_{1}) > s(C_{0}, I_{1}) \\
        0              & \text{otherwise}
    \end{cases}
\end{equation}
where $s(\cdot)$ is the model's score for the image/caption pair.

The second metric is the \textbf{image score}, which measures whether a model can select the correct image, given a caption.
The image score for an example is computed according to:
\begin{equation}\label{eq:image-score}
        is(C_{0},I_{0},C_{1},I_{1})= 
    \begin{cases}
        1 & \text{if}\  s(C_{0}, I_{0}) > s(C_{0}, I_{1})\\
        & \ \ \text{and}\ s(C_{1}, I_{1}) > s(C_{1}, I_{0}) \\
        0              & \text{otherwise}
    \end{cases}
\end{equation}

Our final metric \textbf{group score} combines the previous two, which measures if every combination for a given example is correctly scored by the model.
The group score for an example is computed according to:
\begin{equation}\label{eq:group-score}
        gs(C_{0},I_{0},C_{1},I_{1})= 
    \begin{cases}
        1 & \text{if}\  ts(C_{0},I_{0},C_{1},I_{1})  \\
         & \ \ \text{and}\ is(C_{0},I_{0},C_{1},I_{1})\\
        0              & \text{otherwise}
    \end{cases}
\end{equation}

\subsubsection{Accuracy}

We also add three additional accuracy metrics. These are similar to the previous ones, but accuracy is 0.5 when one of the pairs is correct.

Given images $I_0$ and $I_{1}$ and captions $C_{0}$ and $C_{1}$, the \textbf{text accuracy} for an example $(C_{0},I_{0},C_{1},I_{1})$ is computed according to:
\begin{equation}\label{eq:text-accuracy}
        ta(C_{0},I_{0},C_{1},I_{1})= 
    \begin{cases}
        1 & \text{if}\  s(C_{0}, I_{0}) > s(C_{1}, I_{0}) \\
        & \ \ \text{and}\ s(C_{1}, I_{1}) > s(C_{0}, I_{1}) \\
        0.5 & \text{if}\  s(C_{0}, I_{0}) > s(C_{1}, I_{0}) \\
        & \ \ \text{xor}\ s(C_{1}, I_{1}) > s(C_{0}, I_{1}) \\
        0              & \text{otherwise}
    \end{cases}
\end{equation}
where $s(\cdot)$ is the model's score for the image/caption pair.

The \textbf{image accuracy} for an example is computed according to:
\begin{equation}\label{eq:image-accuracy}
        ia(C_{0},I_{0},C_{1},I_{1})= 
    \begin{cases}
        1 & \text{if}\  s(C_{0}, I_{0}) > s(C_{0}, I_{1})\\
        & \ \ \text{and}\ s(C_{1}, I_{1}) > s(C_{1}, I_{0}) \\
        0.5 & \text{if}\  s(C_{0}, I_{0}) > s(C_{0}, I_{1})\\
        & \ \ \text{xor}\ s(C_{1}, I_{1}) > s(C_{1}, I_{0}) \\
        0              & \text{otherwise}
    \end{cases}
\end{equation}

The \textbf{group accuracy} in our framework is computed according to:
\begin{equation}\label{eq:group-accuracy}
        ga(C_{0},I_{0},C_{1},I_{1})= 
        (ta(C_{0},I_{0},C_{1},I_{1}) + ia(C_{0},I_{0},C_{1},I_{1})) / 2\\
\end{equation}
