{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winoground CLIP Retrieval\n",
    "\n",
    "Retrieve images from Winoground captions and images using CLIP Retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT9FwUjk_lRD"
   },
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install clip-retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CLIP Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from clip_retrieval.clip_client import ClipClient, Modality\n",
    "\n",
    "def log_result(result):\n",
    "    id, caption, url, similarity = result[\"id\"], result[\"caption\"], result[\"url\"], result[\"similarity\"]\n",
    "    print(f\"id: {id}\")\n",
    "    print(f\"caption: {caption}\")\n",
    "    print(f\"url: {url}\")\n",
    "    print(f\"similarity: {similarity}\")\n",
    "    display(Image(url=url, unconfined=True))\n",
    "\n",
    "client = ClipClient(\n",
    "    url=\"https://knn5.laion.ai/knn-service\",\n",
    "    indice_name=\"laion5B\",\n",
    "    aesthetic_score=9,\n",
    "    aesthetic_weight=0.5,\n",
    "    modality=Modality.IMAGE,\n",
    "    num_images=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query by text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 518836491\n",
      "caption: orange cat with supicious look stock photo\n",
      "url: https://media.istockphoto.com/photos/orange-cat-with-supicious-look-picture-id907595140?k=6&amp;m=907595140&amp;s=612x612&amp;w=0&amp;h=4CTvSxNvv4sxSCPxViryha4kAjuxDbrXM5vy4VPOuzk=\n",
      "similarity: 0.5591725707054138\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://media.istockphoto.com/photos/orange-cat-with-supicious-look-picture-id907595140?k=6&amp;m=907595140&amp;s=612x612&amp;w=0&amp;h=4CTvSxNvv4sxSCPxViryha4kAjuxDbrXM5vy4VPOuzk=\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_results = client.query(text=\"an image of a cat\")\n",
    "log_result(cat_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 574870177\n",
      "caption: Palm trees in Orlando, Florida\n",
      "url: https://www.polefitfreedom.com/wp-content/uploads/2018/03/Orlando.jpg\n",
      "similarity: 0.9619366526603699\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.polefitfreedom.com/wp-content/uploads/2018/03/Orlando.jpg\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beach_results = client.query(image=\"https://github.com/rom1504/clip-retrieval/raw/main/tests/test_clip_inference/test_images/321_421.jpg\")\n",
    "log_result(beach_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query by embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip  # pylint: disable=import-outside-toplevel\n",
    "import torch\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=\"cpu\", jit=True)\n",
    "\n",
    "import urllib\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def download_image(url):\n",
    "    urllib_request = urllib.request.Request(\n",
    "        url,\n",
    "        data=None,\n",
    "        headers={\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:72.0) Gecko/20100101 Firefox/72.0\"},\n",
    "    )\n",
    "    with urllib.request.urlopen(urllib_request, timeout=10) as r:\n",
    "        img_stream = io.BytesIO(r.read())\n",
    "    return img_stream\n",
    "\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "def get_text_emb(text):\n",
    "    with torch.no_grad():\n",
    "        text_emb = model.encode_text(clip.tokenize([text], truncate=True).to(\"cpu\"))\n",
    "        text_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
    "        text_emb = text_emb.cpu().detach().numpy().astype(\"float32\")[0]\n",
    "    return text_emb\n",
    "\n",
    "from PIL import Image as pimage\n",
    "\n",
    "def get_image_emb_url(image_url):\n",
    "    with torch.no_grad():\n",
    "        image = pimage.open(download_image(image_url))\n",
    "        image_emb = model.encode_image(preprocess(image).unsqueeze(0).to(\"cpu\"))\n",
    "        image_emb /= image_emb.norm(dim=-1, keepdim=True)\n",
    "        image_emb = image_emb.cpu().detach().numpy().astype(\"float32\")[0]\n",
    "        return image_emb\n",
    "    \n",
    "def get_image_emb(image_path):\n",
    "    with torch.no_grad():\n",
    "        image = pimage.open(image_path)\n",
    "        image_emb = model.encode_image(preprocess(image).unsqueeze(0).to(\"cpu\"))\n",
    "        image_emb /= image_emb.norm(dim=-1, keepdim=True)\n",
    "        image_emb = image_emb.cpu().detach().numpy().astype(\"float32\")[0]\n",
    "        return image_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2195290014\n",
      "caption: CTS29 100% Cotton T Shirt Crew Neck V Neck Long Sleeves Solid Maroon\n",
      "url: https://cdn.shopify.com/s/files/1/1531/9423/products/CTS29_100_Cotton_T_Shirt_Crew_Neck_V_Neck_Long_Sleeves_Solid_Maroon_large.jpg?v=1476875650\n",
      "similarity: 0.5375759601593018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.shopify.com/s/files/1/1531/9423/products/CTS29_100_Cotton_T_Shirt_Crew_Neck_V_Neck_Long_Sleeves_Solid_Maroon_large.jpg?v=1476875650\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_tshirt_text_emb = get_text_emb(\"red tshirt\")\n",
    "red_tshirt_results = client.query(embedding_input=red_tshirt_text_emb.tolist())\n",
    "log_result(red_tshirt_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2463946620\n",
      "caption: 8c7889e0b92b Cinderella Divine 1295 Long Chiffon Grecian Royal Blue Dress Mid Length  Sleeves V Neck ...\n",
      "url: https://cdn.shopify.com/s/files/1/1417/0920/products/1295cd-royal-blue_cfcbd4bc-ed74-47c0-8659-c1b8691990df.jpg?v=1527650905\n",
      "similarity: 0.9430058598518372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.shopify.com/s/files/1/1417/0920/products/1295cd-royal-blue_cfcbd4bc-ed74-47c0-8659-c1b8691990df.jpg?v=1527650905\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blue_dress_image_emb = get_image_emb_url(\"https://rukminim1.flixcart.com/image/612/612/kv8fbm80/dress/b/5/n/xs-b165-royal-blue-babiva-fashion-original-imag86psku5pbx2g.jpeg?q=70\")\n",
    "blue_dress_results = client.query(embedding_input=blue_dress_image_emb.tolist())\n",
    "log_result(blue_dress_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2702080924\n",
      "caption: CLEARANCE - Long Chiffon Grecian Red Dress Mid Length Sleeves V Neck (Size Medium)\n",
      "url: https://cdn-img-3.wanelo.com/p/716/c27/0c0/aef7a32a4317370b6f7f14b/x354-q80.jpg\n",
      "similarity: 0.8246004581451416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-img-3.wanelo.com/p/716/c27/0c0/aef7a32a4317370b6f7f14b/x354-q80.jpg\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_tshirt_text_emb =  get_text_emb(\"red tshirt\")\n",
    "blue_dress_image_emb = get_image_emb_url(\"https://rukminim1.flixcart.com/image/612/612/kv8fbm80/dress/b/5/n/xs-b165-royal-blue-babiva-fashion-original-imag86psku5pbx2g.jpeg?q=70\")\n",
    "mean_emb = normalized(red_tshirt_text_emb + blue_dress_image_emb)[0]\n",
    "mean_results = client.query(embedding_input=mean_emb.tolist())\n",
    "log_result(mean_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Query by Winoground Captions and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "winoground = []\n",
    "with open('../data/examples.jsonl') as f:\n",
    "    for line in f:\n",
    "        winoground.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [1:00:15<00:00,  9.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for example in tqdm(winoground):\n",
    "    caption_0 = example[\"caption_0\"]\n",
    "    caption_1 = example[\"caption_1\"]\n",
    "    image_0 = f'../data/images/{example[\"image_0\"]}.png'\n",
    "    image_1 = f'../data/images/{example[\"image_1\"]}.png'\n",
    "    \n",
    "    caption_0_emb = get_text_emb(caption_0)\n",
    "    caption_1_emb = get_text_emb(caption_1)\n",
    "    image_0_emb = get_image_emb(image_0)\n",
    "    image_1_emb = get_image_emb(image_0)\n",
    "    caption_0_image_0_emb = normalized(caption_0_emb + image_0_emb)[0]\n",
    "    caption_0_image_1_emb = normalized(caption_0_emb + image_1_emb)[0]\n",
    "    caption_1_image_0_emb = normalized(caption_1_emb + image_0_emb)[0]\n",
    "    caption_1_image_1_emb = normalized(caption_1_emb + image_1_emb)[0]\n",
    "    \n",
    "    example[\"caption_0_retrieval\"] = client.query(embedding_input=caption_0_emb.tolist())\n",
    "    example[\"caption_1_retrieval\"] = client.query(embedding_input=caption_1_emb.tolist())\n",
    "    example[\"image_0_retrieval\"] = client.query(embedding_input=image_0_emb.tolist())\n",
    "    example[\"image_1_retrieval\"] = client.query(embedding_input=image_1_emb.tolist())\n",
    "    example[\"caption_0_image_0_retrieval\"] = client.query(embedding_input=caption_0_image_0_emb.tolist())\n",
    "    example[\"caption_0_image_1_retrieval\"] = client.query(embedding_input=caption_0_image_1_emb.tolist())\n",
    "    example[\"caption_1_image_0_retrieval\"] = client.query(embedding_input=caption_1_image_0_emb.tolist())\n",
    "    example[\"caption_1_image_1_retrieval\"] = client.query(embedding_input=caption_1_image_1_emb.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clip_retrieval.json', 'w') as f:\n",
    "    json.dump(winoground, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8890164936ba431effa62f548d2e190a63033d8c51925a70e93a060bef4e9d5d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
